# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DfR3nvG5ucmgPyI3rMb1xSxQA9eSvXhO
"""

import streamlit as st
import pandas as pd
import requests
import time
import nltk
import altair as alt

from pyspark.sql import SparkSession
from pyspark.ml.feature import Tokenizer, HashingTF, IDF
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from nltk.sentiment.vader import SentimentIntensityAnalyzer

# Download VADER (only once)
nltk.download("vader_lexicon")

# Cache Spark session
@st.cache_resource
def init_spark():
    return (
        SparkSession.builder
        .appName("NewsSentimentApp")
        .master("local[*]")
        .config("spark.ui.showConsoleProgress", "false")
        .getOrCreate()
    )

spark = init_spark()

# API key
API_KEY = "eefb8c41863048df9e948694f8b52e6a"

# ---------- Helpers ----------
def get_articles(query, limit=5):
    url = f"https://newsapi.org/v2/everything?q={query}&pageSize={limit}&sortBy=publishedAt&apiKey={API_KEY}"
    res = requests.get(url).json()
    items = res.get("articles", [])
    return pd.DataFrame([{"headline": i["title"]} for i in items if i.get("title")])

def tag_sentiment(df):
    vader = SentimentIntensityAnalyzer()

    def score_text(txt):
        val = vader.polarity_scores(txt)["compound"]
        if val > 0.05:
            return "Positive"
        elif val < -0.05:
            return "Negative"
        return "Neutral"

    df["sentiment"] = df["headline"].apply(score_text)
    df["label"] = df["sentiment"].map({"Negative": 0.0, "Neutral": 1.0, "Positive": 2.0})
    return df

def train_model(df):
    sdf = spark.createDataFrame(df)

    # Pipeline
    tok = Tokenizer(inputCol="headline", outputCol="words")
    words = tok.transform(sdf)

    tf = HashingTF(inputCol="words", outputCol="raw")
    tf_data = tf.transform(words)

    idf = IDF(inputCol="raw", outputCol="features")
    idf_model = idf.fit(tf_data)
    vec_data = idf_model.transform(tf_data)

    lr = LogisticRegression(maxIter=10, regParam=0.001)
    model = lr.fit(vec_data)

    acc = MulticlassClassificationEvaluator(
        labelCol="label", predictionCol="prediction", metricName="accuracy"
    ).evaluate(model.transform(vec_data))

    return model, tok, tf, idf_model, acc

def predict_sentiment(df, model, tok, tf, idf_model):
    sdf = spark.createDataFrame(df)
    words = tok.transform(sdf)
    tf_data = tf.transform(words)
    vec_data = idf_model.transform(tf_data)

    preds = model.transform(vec_data).select("headline", "prediction").toPandas()
    preds["sentiment"] = preds["prediction"].map({0.0: "Negative", 1.0: "Neutral", 2.0: "Positive"})
    return preds

# ---------- Streamlit UI ----------
st.set_page_config(page_title="News Sentiment AI", layout="wide")
st.title("📰 Real-time News Sentiment Analysis")

col1, col2 = st.columns([2, 1])
with col1:
    query = st.text_input("Enter a topic:", "AI")
with col2:
    count = st.slider("Articles", 3, 20, 5)

mode = st.radio("Choose mode", ["Train Model", "Predict Only"], horizontal=True)

if st.button("Run Analysis"):
    data = get_articles(query, count)
    if data.empty:
        st.error("⚠️ No news articles found.")
    else:
        if mode == "Train Model":
            labeled = tag_sentiment(data)
            model, tok, tf, idf_model, acc = train_model(labeled)

            st.session_state.update(
                {"model": model, "tok": tok, "tf": tf, "idf": idf_model}
            )

            st.success(f"Model trained ✅ Accuracy: {acc:.2%}")
            st.subheader("📊 Training Data")
            st.dataframe(labeled[["headline", "sentiment"]])

        else:  # Prediction mode
            if "model" not in st.session_state:
                st.error("Please train the model first.")
            else:
                preds = predict_sentiment(
                    data,
                    st.session_state["model"],
                    st.session_state["tok"],
                    st.session_state["tf"],
                    st.session_state["idf"],
                )

                st.subheader("🔮 Predictions")
                st.dataframe(preds[["headline", "sentiment"]])

                st.subheader("📡 Live Stream Simulation")
                for _, r in preds.iterrows():
                    st.write(f"**{r['headline']}** → {r['sentiment']}")
                    time.sleep(0.5)

                st.subheader("📈 Sentiment Distribution")
                chart_data = preds.groupby("sentiment").size().reset_index(name="count")
                chart = (
                    alt.Chart(chart_data)
                    .mark_bar()
                    .encode(x="sentiment", y="count", color="sentiment")
                )
                st.altair_chart(chart, use_container_width=True)