# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1uobwOq6FgAhU5uRlCGhMbnSxcgeWuDwV
"""

import streamlit as st
import pandas as pd
import requests
import time
import nltk
import altair as alt

from pyspark.sql import SparkSession
from pyspark.ml.feature import Tokenizer, HashingTF, IDF
from pyspark.ml.classification import LogisticRegression
from pyspark.ml.evaluation import MulticlassClassificationEvaluator
from nltk.sentiment.vader import SentimentIntensityAnalyzer


# Setup
# ---------------------------

nltk.download("vader_lexicon", quiet=True)

@st.cache_resource
def get_spark():
    """Start or reuse a Spark session."""
    return (
        SparkSession.builder
        .appName("NewsSentimentStreaming")
        .master("local[*]")
        .config("spark.ui.showConsoleProgress", "false")
        .getOrCreate()
    )

spark = get_spark()

# Import userdata to access Colab secrets
from google.colab import userdata

NEWS_API_KEY = userdata.get("NEWS_API_KEY")

# Sentiment Labeling
# ---------------------------

def label_sentiment(df: pd.DataFrame) -> pd.DataFrame:
    """Apply VADER sentiment analysis and assign numeric labels."""
    sia = SentimentIntensityAnalyzer()

    def classify(text: str) -> str:
        score = sia.polarity_scores(text)["compound"]
        if score > 0.05:
            return "Positive"
        elif score < -0.05:
            return "Negative"
        return "Neutral"

    df["sentiment"] = df["title"].apply(classify)
    label_map = {"Positive": 2.0, "Neutral": 1.0, "Negative": 0.0}
    df["label"] = df["sentiment"].map(label_map)
    return df

# Spark ML Pipeline Helpers
# ---------------------------

def train_model(df_pd: pd.DataFrame):
    """Train logistic regression model with Spark ML pipeline."""
    df_spark = spark.createDataFrame(df_pd)

    tokenizer = Tokenizer(inputCol="title", outputCol="words")
    words_data = tokenizer.transform(df_spark)

    hashingTF = HashingTF(inputCol="words", outputCol="rawFeatures")
    featurized_data = hashingTF.transform(words_data)

    idf = IDF(inputCol="rawFeatures", outputCol="features")
    idf_model = idf.fit(featurized_data)
    rescaled_data = idf_model.transform(featurized_data)

    lr = LogisticRegression(maxIter=10, regParam=0.001)
    model = lr.fit(rescaled_data)

    evaluator = MulticlassClassificationEvaluator(
        labelCol="label", predictionCol="prediction", metricName="accuracy"
    )
    accuracy = evaluator.evaluate(model.transform(rescaled_data))

    return model, tokenizer, hashingTF, idf_model, accuracy


def predict(model, tokenizer, hashingTF, idf_model, df_pd: pd.DataFrame) -> pd.DataFrame:
    """Run predictions on new articles."""
    df_spark = spark.createDataFrame(df_pd)

    words_data = tokenizer.transform(df_spark)
    featurized_data = hashingTF.transform(words_data)
    rescaled_data = idf_model.transform(featurized_data)

    predictions = model.transform(rescaled_data).select("title", "prediction")
    df_out = predictions.toPandas()

    label_map_reverse = {2.0: "Positive", 1.0: "Neutral", 0.0: "Negative"}
    df_out["sentiment"] = df_out["prediction"].map(label_map_reverse)
    return df_out

# Streamlit UI
# ---------------------------

st.title("üì∞ PySpark News Sentiment Dashboard")

topic = st.text_input("Topic", "technology")
mode = st.radio("Mode", ["Bootstrap", "Predict"])
num_articles = st.slider("Number of articles", 3, 20, 5)

if st.button("Run"):
    df_news = fetch_news(topic, num_articles)

    if df_news.empty:
        st.error("No news found.")
    else:
        if mode == "Bootstrap":
            # Label and train
            df_labeled = label_sentiment(df_news)
            model, tokenizer, hashingTF, idf_model, accuracy = train_model(df_labeled)

            st.session_state.update({
                "model": model,
                "tokenizer": tokenizer,
                "hashingTF": hashingTF,
                "idf_model": idf_model,
            })

            st.success("‚úÖ Model trained successfully!")
            st.info(f"Training Accuracy: {accuracy:.2%}")
            st.subheader("Bootstrap Data")
            st.write(df_labeled[["title", "sentiment"]])

        elif mode == "Predict":
            if "model" not in st.session_state:
                st.error("‚ö†Ô∏è Run Bootstrap first!")
            else:
                preds = predict(
                    st.session_state["model"],
                    st.session_state["tokenizer"],
                    st.session_state["hashingTF"],
                    st.session_state["idf_model"],
                    df_news,
                )

                st.subheader("Predictions")
                st.write(preds[["title", "sentiment"]])

                # Streaming simulation
                st.subheader("Streaming Simulation")
                for _, row in preds.iterrows():
                    st.write(f"**{row['title']}** ‚Üí {row['sentiment']}")
                    time.sleep(0.5)

                # Sentiment distribution chart
                chart_data = preds.groupby("sentiment").size().reset_index(name="count")
                chart = (
                    alt.Chart(chart_data)
                    .mark_bar()
                    .encode(x="sentiment", y="count", color="sentiment")
                )
                st.altair_chart(chart, use_container_width=True)

