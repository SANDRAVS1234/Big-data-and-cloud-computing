{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import streamlit as st\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "from pyspark.sql.types import StringType\n",
        "from pyspark.ml.feature import Tokenizer, StopWordsRemover, HashingTF, IDF\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "cA-5und2Ywzr"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. Setup Spark Session\n",
        "# --------------------------\n",
        "spark = SparkSession.builder \\\n",
        "    .appName(\"RealTimeNewsSentiment\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "7BAb9B_TkFbi"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Fetch Real-Time News\n",
        "# --------------------------\n",
        "def fetch_news(api_key, query=\"technology\", language=\"en\", page_size=20):\n",
        "    url = f\"https://newsapi.org/v2/top-headlines?q={query}&language={language}&pageSize={page_size}&apiKey={api_key}\"\n",
        "    response = requests.get(url)\n",
        "    data = response.json()\n",
        "    articles = data.get(\"articles\", [])\n",
        "    headlines = [a[\"title\"] for a in articles if a[\"title\"]]\n",
        "    return headlines\n"
      ],
      "metadata": {
        "id": "NSc5LGbMkI8L"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3. Prepare Training Data\n",
        "# --------------------------\n",
        "# Small sample dataset for demonstration\n",
        "train_data = [\n",
        "    (\"Stocks rally as tech shares soar\", \"Positive\"),\n",
        "    (\"Company reports record profits\", \"Positive\"),\n",
        "    (\"Market crashes amid economic fears\", \"Negative\"),\n",
        "    (\"Political tensions drive uncertainty\", \"Negative\"),\n",
        "    (\"New breakthrough in cancer research\", \"Positive\"),\n",
        "    (\"Floods devastate several regions\", \"Negative\"),\n",
        "]\n",
        "\n",
        "train_df = spark.createDataFrame(train_data, [\"text\", \"label\"])\n"
      ],
      "metadata": {
        "id": "Wn0OlHiIkyu8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. Build Spark ML Pipeline\n",
        "# --------------------------\n",
        "tokenizer = Tokenizer(inputCol=\"text\", outputCol=\"words\")\n",
        "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
        "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"rawFeatures\", numFeatures=1000)\n",
        "idf = IDF(inputCol=\"rawFeatures\", outputCol=\"features\")\n",
        "lr = LogisticRegression(labelCol=\"labelIndex\", featuresCol=\"features\")\n",
        "\n",
        "# StringIndexer to convert labels\n",
        "from pyspark.ml.feature import StringIndexer\n",
        "indexer = StringIndexer(inputCol=\"label\", outputCol=\"labelIndex\")\n",
        "\n",
        "pipeline = Pipeline(stages=[tokenizer, remover, hashingTF, idf, indexer, lr])\n",
        "\n",
        "# Fit the model\n",
        "model = pipeline.fit(train_df)"
      ],
      "metadata": {
        "id": "dRL0jNVak2bQ"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. Sentiment Prediction UDF (Fallback with TextBlob if needed)\n",
        "# --------------------------\n",
        "def get_sentiment(text):\n",
        "    analysis = TextBlob(text).sentiment.polarity\n",
        "    return \"Positive\" if analysis >= 0 else \"Negative\"\n",
        "\n",
        "sentiment_udf = udf(get_sentiment, StringType())\n"
      ],
      "metadata": {
        "id": "zrlcmGafk7D8"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. Streamlit Dashboard\n",
        "# --------------------------\n",
        "def run_dashboard(api_key):\n",
        "    st.title(\"ðŸ“° Real-Time News Sentiment Dashboard (PySpark + Streamlit)\")\n",
        "\n",
        "    query = st.text_input(\"Enter topic:\", \"technology\")\n",
        "    if st.button(\"Fetch News\"):\n",
        "        headlines = fetch_news(api_key, query=query)\n",
        "\n",
        "        if not headlines:\n",
        "            st.warning(\"No news found.\")\n",
        "            return\n",
        "\n",
        "        # Convert to Spark DataFrame\n",
        "        df = spark.createDataFrame([(h,) for h in headlines], [\"text\"])\n",
        "\n",
        "        # Predict with PySpark model\n",
        "        preds = model.transform(df)\n",
        "\n",
        "        # Map predictions back to Positive/Negative\n",
        "        label_indexer = dict(enumerate(model.stages[-2].labels))  # from StringIndexer\n",
        "        preds = preds.withColumn(\"sentiment\", col(\"prediction\").cast(\"int\"))\n",
        "        preds = preds.withColumn(\"sentiment\", udf(lambda x: label_indexer[x], StringType())(col(\"sentiment\")))\n",
        "\n",
        "        # Convert to Pandas for dashboard\n",
        "        pdf = preds.select(\"text\", \"sentiment\").toPandas()\n",
        "\n",
        "        st.dataframe(pdf)\n",
        "\n",
        "        # Sentiment counts\n",
        "        counts = pdf[\"sentiment\"].value_counts()\n",
        "        st.bar_chart(counts)"
      ],
      "metadata": {
        "id": "e_yJXEjRlAXE"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 7. Run App\n",
        "# --------------------------\n",
        "if __name__ == \"__main__\":\n",
        "    # ðŸ”‘ Replace with your NewsAPI key\n",
        "    API_KEY = \"eefb8c41863048df9e948694f8b52e6a\"\n",
        "\n",
        "    run_dashboard(API_KEY)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dyT0Jd23lRT5",
        "outputId": "5bc05c34-0c1f-4f6b-fd31-0fe2a0901f64"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-09-26 10:35:05.459 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.678 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-09-26 10:35:05.679 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.681 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.683 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.686 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.687 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.690 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.692 Session state does not function when running a script without `streamlit run`\n",
            "2025-09-26 10:35:05.693 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.695 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.696 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.698 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.700 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.700 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.704 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.706 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-09-26 10:35:05.708 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "00vObS87luVr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}